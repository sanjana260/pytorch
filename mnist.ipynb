{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f6769de",
   "metadata": {},
   "source": [
    "# MNIST Example\n",
    "Working on the MNIST dataset using Pytorch. Reference: https://docs.pytorch.org/tutorials/beginner/nn_tutorial.html\n",
    "\n",
    "### Data Download\n",
    "Start by downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce6b4081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"https://github.com/pytorch/tutorials/raw/main/_static/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee96ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "# STored in pickle format\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307c6b22",
   "metadata": {},
   "source": [
    "### Visualize Image\n",
    "Visualize one image as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "608b19de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "pyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
    "# ``pyplot.show()`` only if not on Colab\n",
    "try:\n",
    "    import google.colab\n",
    "except ImportError:\n",
    "    pyplot.show()\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a14f50f",
   "metadata": {},
   "source": [
    "### Convert to Tensor\n",
    "Convert all data to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "901dadae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "torch.Size([50000, 784])\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")\n",
    "n, c = x_train.shape\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a6837c",
   "metadata": {},
   "source": [
    "### Simple Model\n",
    "Simple linear model for starters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5a41e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "weights = torch.randn(784, 10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70149f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784, 10]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(weights.shape, bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b094eccb",
   "metadata": {},
   "source": [
    "** Log Softmax **\n",
    "\n",
    "Log softmax involves taking log of softmax function. It simplifies to:\n",
    "\n",
    "log(exp(xi)/sum(exp(xi)))\n",
    "= xi - log(sum(exp(xi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6978b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): # Defining softmax \n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "\n",
    "def model(xb):\n",
    "    return log_softmax(xb @ weights + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98101ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.8457, -2.1009, -2.5715, -2.3403, -2.6049, -1.6739, -1.9808, -2.3817,\n",
      "        -2.5670, -2.5471], grad_fn=<SelectBackward0>) torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "bs = 64  # batch size\n",
    "\n",
    "xb = x_train[0:bs]  # a mini-batch from x\n",
    "preds = model(xb)  # predictions\n",
    "preds[0], preds.shape\n",
    "print(preds[0], preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c8cb865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 5, 1, 5, 2, 8, 8, 5, 2, 5, 5, 9, 2, 3, 6, 5, 5, 5, 4, 5, 8, 5, 5, 5,\n",
       "        5, 5, 2, 2, 5, 7, 6, 1, 7, 5, 5, 5, 7, 5, 7, 5, 6, 5, 2, 5, 2, 2, 5, 5,\n",
       "        2, 5, 1, 5, 3, 5, 2, 5, 5, 5, 8, 5, 4, 3, 5, 4])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(preds, dim=1) # Getting the digit predictions for each item in the mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb39e8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 3, 7, 0, 9, 0, 8, 5, 5, 2, 4, 5, 0, 8, 4, 8])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0afa600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.5471, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0,yb[0]] # We want the value for the target digit to be maximized.\n",
    "# So we minimize the negative of this function. That is negative log likelihood loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f221cdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target): # negative log likelihood loss function\n",
    "    return -input[range(target.shape[0]), target].mean()\n",
    "\n",
    "loss_func = nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ce65c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4839, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "print(loss_func(preds, yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f11a59e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0938)\n"
     ]
    }
   ],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()\n",
    "print(accuracy(preds, yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8b33153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(n - 1) // bs + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb3f3e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.17590491473674774\n",
      "Epoch: 1, Loss: 0.16923442482948303\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "lr = 0.5  # learning rate\n",
    "epochs = 2  # how many epochs to train for\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        #         set_trace()\n",
    "        # Getting the batch for current iteration\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "\n",
    "        # Getting predictions (forward pass)\n",
    "        pred = model(xb)\n",
    "\n",
    "        # Getting loss\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        # Automatic backward prop using pytorch\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating weights\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1709eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0827, grad_fn=<NegBackward0>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "202b66c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 8, 6,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(model(x_valid), dim=1) # Predictions for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1cd49063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9250)\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(model(x_valid), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f205dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
